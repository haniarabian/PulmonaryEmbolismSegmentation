# -*- coding: utf-8 -*-
"""Training_process.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pYzGRGOg0Lw5IVTxdBzRrLku47MxtP48
"""

# Mount to your google drive to get access to your data
import os
import shutil
import pandas as pd
import numpy as np
from google.colab import drive
drive.mount('/content/drive')

# Unzip your data folder
!unzip /content/drive/MyDrive/data/png.zip -d .

# Split your data to different folders

# Negative subject
neg_subs = [2, 31, 115, 123]

# Remove difficult subject from the data
difficult_subs = [28, 34, 44, 56, 76, 82, 93, 95, 97, 101, 113]
src_path = "/content/png/train"
dest_path = "/content/png/difficult"
for sub in difficult_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))

src_path = "/content/png/trainannot"
dest_path = "/content/png/difficultannot"
for sub in difficult_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))


# Split unseen subject from the data
unseen_subs = [5,17,23,37,47,48,63,73,86,103,124]
src_path = "/content/png/train"
dest_path = "/content/png/unseen"
for sub in unseen_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))

src_path = "/content/png/trainannot"
dest_path = "/content/png/unseenannot"
for sub in unseen_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))

# Divide data into 5-fold
testindex = np.array(pd.read_excel('/content/drive/MyDrive/index/new_test_idx.xlsx' , header=None, names=None, index_col=None))

# folder number K
K = 1
val_subs = testindex[K-1 , :]
src_path = "/content/png/train"
dest_path = "/content/png/val"
for sub in val_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))

src_path = "/content/png/trainannot"
dest_path = "/content/png/valannot"
for sub in val_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))

idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
test_subs = val_subs[idx]
src_path = "/content/png/val"
dest_path = "/content/png/test"
for sub in test_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))

src_path = "/content/png/valannot"
dest_path = "/content/png/testannot"
for sub in test_subs:
  shutil.move(os.path.join(src_path, f"P{sub}_T1"), os.path.join(dest_path, f"P{sub}_T1"))

# Commented out IPython magic to ensure Python compatibility.
# Change the current direction to the network folder
# %cd /content/drive/MyDrive/PE_SEG/attention-cnn-MS-segmentation

"""Train"""

#set the dropout to 0.3 from layers
#set -lr -->learning_rate -->1e-4
#set -lrde -->learning_rate_decay_every-->4
#set -wd -->weight_decay --> 1e-4
#set loss function -->combined loss (DICE+FOCAL)

# Train network with training dataset
!python train.py  -dp "/content/png" -fcnl 103 --weights-path /content/drive/MyDrive/Weights_1

"""Test or Evaluation"""

import gc
import torch
import shutil
import cv2 as cv
import numpy as np
import pandas as pd
import tensorflow as tf
from numpy import asarray
from numpy import savetxt
import matplotlib.pyplot as plt
from scipy.spatial.distance import directed_hausdorff
from scipy.ndimage import label, binary_dilation

def patient_eval(val_path, infer_path):
    per = 95
    haus = 0
    file_name = os.listdir(infer_path)
    out = []
    orig = []
    for name in file_name:
      img_name = name
      out_path = os.path.join(infer_path, img_name)
      out_slice = cv.imread(out_path, cv.IMREAD_GRAYSCALE)
      out.append(out_slice)
      img_name = img_name.replace('flair_pp' , 'mask1')
      orig_path = os.path.join(val_path, img_name)
      orig_slice = cv.imread(orig_path, cv.IMREAD_GRAYSCALE)
      orig.append(orig_slice)

    out = (np.array(out) > 0).astype(np.uint8)
    orig = (np.array(orig) > 0).astype(np.uint8)

    out_points = np.argwhere(out)
    orig_points = np.argwhere(orig)

    if len(out_points) == 0 or len(orig_points) == 0:
      flag = 1
    else:
      flag = 0
      d1 = directed_hausdorff(out_points, orig_points)[0]
      d2 = directed_hausdorff(orig_points, out_points)[0]
      hd1 = np.percentile(np.min(d1), per)
      hd2 = np.percentile(np.min(d2), per)
      haus = max(hd1, hd2)

    tp = np.sum((out == 1) & (orig == 1))
    tn = np.sum((out == 0) & (orig == 0))
    fp = np.sum((out == 1) & (orig == 0))
    fn = np.sum((out == 0) & (orig == 1))

    p = [tp, tn, fp, fn, round(haus,4)]
    return p

def slice_eval(val_path, infer_path):
    per = 95
    haus = 0
    file_name = os.listdir(infer_path)
    out = []
    orig = []
    slices = []
    for name in file_name:
      flag = 0
      img_name = name
      out_path = os.path.join(infer_path, img_name)
      out = cv.imread(out_path, cv.IMREAD_GRAYSCALE)

      img_name = img_name.replace('flair_pp' , 'mask1')
      orig_path = os.path.join(val_path, img_name)
      orig = cv.imread(orig_path, cv.IMREAD_GRAYSCALE)


      out = (np.array(out) > 0).astype(np.uint8)
      orig = (np.array(orig) > 0).astype(np.uint8)

      out_points = np.argwhere(out)
      orig_points = np.argwhere(orig)

      if len(out_points) == 0 or len(orig_points) == 0:
        flag = 1
      else:
        flag = 0
        d1 = directed_hausdorff(out_points, orig_points)[0]
        d2 = directed_hausdorff(orig_points, out_points)[0]
        hd1 = np.percentile(np.min(d1), per)
        hd2 = np.percentile(np.min(d2), per)
        haus = max(hd1, hd2)

      tp = np.sum((out == 1) & (orig == 1))
      tn = np.sum((out == 0) & (orig == 0))
      fp = np.sum((out == 1) & (orig == 0))
      fn = np.sum((out == 0) & (orig == 1))
      p = [tp, tn, fp, fn, round(haus,4)]
      slices.append(p)
    return slices

def fpr_fnr(val_path, infer_path):
    file_name = os.listdir(infer_path)
    out = []
    orig = []
    tp, fp, tn, fn = 0, 0, 0, 0
    for name in file_name:
      img_name = name
      out_path = os.path.join(infer_path, img_name)
      out = cv.imread(out_path, cv.IMREAD_GRAYSCALE)

      img_name = img_name.replace('flair_pp' , 'mask1')
      orig_path = os.path.join(val_path, img_name)
      orig = cv.imread(orig_path, cv.IMREAD_GRAYSCALE)

      out = np.array(out)
      orig = np.array(orig)
      out[out > 0] = 1
      orig[orig > 0] = 1

      if np.sum(orig) > 0:
        if np.sum(out) > 0:
          tp += 1
        else:
          fn += 1
      else:
        if np.sum(out) > 0:
          fp += 1
        else:
          tn += 1

    se_pe = tp/(tp+fn + 1e-6)
    fpr_pe = fp / (fp+tn + 1e-6)
    fnr_pe = fn/ (tp+fn + 1e-6)
    p = [se_pe, fpr_pe, fnr_pe]
    return p

def patient_emboli_eval(val_path, infer_path):
    per = 95
    min_size = 15
    min_d = 15
    haus, se_pe, fpr_pe, fnr_pe, false_pe, missed_pe = 0, 0, 0, 0, 0, 0
    file_name = os.listdir(infer_path)
    out = []
    orig = []
    for name in file_name:
      img_name = name
      out_path = os.path.join(infer_path, img_name)
      out_slice = cv.imread(out_path, cv.IMREAD_GRAYSCALE)
      out.append(out_slice)
      img_name = img_name.replace('flair_pp' , 'mask1')
      orig_path = os.path.join(val_path, img_name)
      orig_slice = cv.imread(orig_path, cv.IMREAD_GRAYSCALE)
      orig.append(orig_slice)

    out = (np.array(out) > 0).astype(np.uint8)
    orig = (np.array(orig) > 0).astype(np.uint8)

    out_points = np.argwhere(out)
    orig_points = np.argwhere(orig)

    if len(out_points) == 0 or len(orig_points) == 0:
      flag = 1
    else:
      flag = 0
      d1 = directed_hausdorff(out_points, orig_points)[0]
      d2 = directed_hausdorff(orig_points, out_points)[0]
      hd1 = np.percentile(np.min(d1), per)
      hd2 = np.percentile(np.min(d2), per)
      haus = max(hd1, hd2)


    orig_labels , num_orig = label(orig)
    out_labels , num_out = label(out)

    for i in range(1, num_out + 1):
      if np.sum(out_labels == i) < min_size:
        out[out_labels == i] = 0

    structure = np.ones((min_d, min_d, min_d))
    merged_mask = binary_dilation(out, structure)
    merged_mask, _ = label(merged_mask)
    out = merged_mask
    out[out > 0] = 1

    out_labels , num_out = label(out)
    detected_pe = sum(np.any(out[orig_labels == i]) for i in range(1, num_orig + 1))
    false_pe = sum(not np.any(orig[out_labels == i]) for i in range(1, num_out + 1))
    missed_pe = num_orig - detected_pe

    se_pe = detected_pe/(num_orig + 1e-6)
    fpr_pe = false_pe / (num_out + 1e-6)
    fnr_pe = missed_pe/ (num_orig + 1e-6)
    p = [round(haus,4), round(se_pe,4), round(fpr_pe,4), round(fnr_pe,4), false_pe, missed_pe]
    del out, orig, out_points, orig_points
    gc.collect()
    return p

def slice_emboli_eval(val_path, infer_path):
    per = 95
    min_size = 15
    min_d = 15
    haus, se_pe, fpr_pe, fnr_pe, false_pe, missed_pe = 0, 0, 0, 0, 0, 0
    file_name = os.listdir(infer_path)
    out = []
    orig = []
    slices = []
    for name in file_name:
      flag = 0
      img_name = name
      out_path = os.path.join(infer_path, img_name)
      out = cv.imread(out_path, cv.IMREAD_GRAYSCALE)

      img_name = img_name.replace('flair_pp' , 'mask1')
      orig_path = os.path.join(val_path, img_name)
      orig = cv.imread(orig_path, cv.IMREAD_GRAYSCALE)


      out = (np.array(out) > 0).astype(np.uint8)
      orig = (np.array(orig) > 0).astype(np.uint8)

      out_points = np.argwhere(out)
      orig_points = np.argwhere(orig)

      if len(out_points) == 0 or len(orig_points) == 0:
        flag = 1
      else:
        flag = 0
        d1 = directed_hausdorff(out_points, orig_points)[0]
        d2 = directed_hausdorff(orig_points, out_points)[0]
        hd1 = np.percentile(np.min(d1), per)
        hd2 = np.percentile(np.min(d2), per)
        haus = max(hd1, hd2)

      orig_labels , num_orig = label(orig)
      out_labels , num_out = label(out)

      for i in range(1, num_out + 1):
        if np.sum(out_labels == i) < min_size:
          out[out_labels == i] = 0

      structure = np.ones((min_d, min_d))
      merged_mask = binary_dilation(out, structure)
      merged_mask, _ = label(merged_mask)
      out = merged_mask
      out[out > 0] = 1

      out_labels , num_out = label(out)
      detected_pe = sum(np.any(out[orig_labels == i]) for i in range(1, num_orig + 1))
      false_pe = sum(not np.any(orig[out_labels == i]) for i in range(1, num_out + 1))
      missed_pe = num_orig - detected_pe

      se_pe = detected_pe/(num_orig + 1e-6)
      fpr_pe = false_pe / (num_out + 1e-6)
      fnr_pe = missed_pe/ (num_orig + 1e-6)
      p = [round(haus,4), round(se_pe,4), round(fpr_pe,4), round(fnr_pe,4), false_pe, missed_pe]
      slices.append(p)
      del out, orig, out_points, orig_points
      gc.collect()
    return slices

infer_path = "/content/drive/MyDrive/PE_SEG/attention-cnn-MS-segmentation/inference_outputs"

"""Select the best epoch by its name. For example: weights-1-1-1.pth

Define the image name. For example patient number 2: P2_T1
"""

!rm -rf /content/drive/MyDrive/PE_SEG/attention-cnn-MS-segmentation/inference_outputs
!python infer.py -fcnl 103 --inference-folder-path /content/png/test/P2_T1 --weights-path /content/drive/MyDrive/Weights_1/weights-1-1-1.pth
val_path = "/content/png/testannot/P2_T1"
Eval_pixel_patient = patient_eval(val_path, infer_path)
Eval_pixel_slice = slice_eval(val_path, infer_path)
Eval_slice_patient = fpr_fnr(val_path, infer_path)
Eval_emboli_patient = patient_emboli_eval(val_path, infer_path)
Eval_emboli_slice = slice_emboli_eval(val_path, infer_path)

Eval_pixel_patient
Eval_pixel_slice
Eval_slice_patient
Eval_emboli_patient
Eval_emboli_slice